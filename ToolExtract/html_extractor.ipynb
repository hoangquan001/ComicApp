{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yoxqp1wzhQiM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jmespath\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting parsel\n",
            "  Downloading parsel-1.9.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "     ------------------------------------ 235.5/235.5 kB 801.6 kB/s eta 0:00:00\n",
            "Collecting lxml\n",
            "  Downloading lxml-5.2.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
            "     ---------------------------------------- 3.8/3.8 MB 7.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from parsel) (21.3)\n",
            "Collecting w3lib>=1.19.0\n",
            "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
            "Collecting cssselect>=1.2.0\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->parsel) (2.4.7)\n",
            "Installing collected packages: w3lib, unidecode, lxml, jmespath, cssselect, parsel\n",
            "Successfully installed cssselect-1.2.0 jmespath-1.0.1 lxml-5.2.0 parsel-1.9.0 unidecode-1.3.8 w3lib-2.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install jmespath parsel unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gCzx9ibLhXFc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import jmespath\n",
        "from parsel import Selector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCQmjdSris6t"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DcQEsiDiJcFT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SaveJSON(fileName,JsonComic):\n",
        "  print(fileName+\"\\n\")\n",
        "  with open(f\"{fileName}.json\", \"w\") as outfile:\n",
        "      json.dump(JsonComic, outfile,indent= 2)\n",
        "\n",
        "\n",
        "def GetComicJSON(urlComic):\n",
        "  response = requests.get(f'https://doctruyenonline.vn/truyen-tranh/{urlComic}')\n",
        "  print(response.status_code)\n",
        "  selector = Selector(text=response.text)\n",
        "  json_data = selector.css(\"script[type='application/json']::text\").get()\n",
        "\n",
        "  data = json.loads(json_data)\n",
        "  expression = jmespath.compile(\n",
        "      \"\"\"\n",
        "      {\n",
        "        \"Title\": props.pageProps.comic[0].nameComic,\n",
        "        \"URL\": props.pageProps.comic[0].urlComic,\n",
        "        \"CoverImage\":   props.pageProps.comic[0].imgComic,\n",
        "        \"CreateAt\":  props.pageProps.comic[0].create_date\n",
        "        \"statusComic\": props.pageProps.comic[0].statusComic\n",
        "        \"Category\":   props.pageProps.comic[0].category[*].name_cate,\n",
        "        \"LastChapter\": props.pageProps.comic[0].lastChapter\n",
        "        \"TotalChapter\": props.pageProps.comic[0].totalChapter\n",
        "        \"Chapters\": props.pageProps.listChapter[0].{urlChapter:urlChapter, dateUpdateChapter: dateUpdateChapter}\n",
        "      }\n",
        "      \"\"\"\n",
        "  )\n",
        "  flat_data = expression.search(data)\n",
        "  return flat_data\n",
        "\n",
        "ListComic = {\"comic\":[]}\n",
        "def fetchData(start, end):\n",
        "    global ListComic\n",
        "    starting = True\n",
        "    idx = 1\n",
        "    expression = jmespath.compile(\n",
        "        \"\"\"\n",
        "        {\n",
        "        \"comic\": props.pageProps.dataComicNew[*].\n",
        "        {\n",
        "            urlComic:urlComic,\n",
        "            totalChapter:totalChapter,\n",
        "            createDateComic:createDateComic,\n",
        "            lastUpdateChapter:lastUpdateChapter\n",
        "            }\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "    idx = start\n",
        "    while idx<=end:\n",
        "        print(f\"fetching {idx}\\n\")\n",
        "        # start = time.time()\n",
        "        response = requests.get(f'https://doctruyenonline.vn/truyen-tranh/tim-truyen?status=2&sort=2&page={idx}')\n",
        "        idx+=1\n",
        "        print(\"status\",response.status_code)\n",
        "        selector = Selector(text=response.text)\n",
        "        json_data = selector.css(\"script[type='application/json']::text\").get()\n",
        "        data = json.loads(json_data)\n",
        "        flat_data = expression.search(data)\n",
        "        if(flat_data[\"comic\"] == []): break\n",
        "        ListComic[\"comic\"].extend(flat_data[\"comic\"])\n",
        "        # end = time.time()\n",
        "        # eplap = end - start\n",
        "\n",
        "        for oneComic in flat_data[\"comic\"]:\n",
        "            urlComic = oneComic[\"urlComic\"]\n",
        "            JsonComic = GetComicJSON(urlComic)\n",
        "            SaveJSON(f\"ComicData/{urlComic}\",JsonComic)\n",
        "    \n",
        "    return ListComic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gsZXDhC-nKAn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fetching 1\n",
            "\n",
            "status 200\n",
            "200\n",
            "ComicData/toi-se-bi-tru-khu-cung-hoang-de\n",
            "\n",
            "200\n",
            "ComicData/hay-de-toi-duoc-hieu-em\n",
            "\n",
            "200\n",
            "ComicData/toi-tuong-ban-than-khong-con-song-duoc-bao-lau\n",
            "\n",
            "200\n",
            "ComicData/gia-dinh-chong-bi-am-anh-boi-toi\n",
            "\n",
            "200\n",
            "ComicData/tinh-yeu-cua-ik-seob\n",
            "\n",
            "200\n",
            "ComicData/phuong-phap-che-giau-dua-con-cua-hoang-de\n",
            "\n",
            "200\n",
            "ComicData/danh-cho-nhan-vat-bi-bo-roi-yeu-thich-nhat-cua-toi\n",
            "\n",
            "200\n",
            "ComicData/serena\n",
            "\n",
            "200\n",
            "ComicData/vo-luyen-dinh-phong\n",
            "\n",
            "200\n",
            "ComicData/quang-doi-con-lai-cua-nu-phu-yeu-menh\n",
            "\n",
            "200\n",
            "ComicData/thieu-soai-vo-ngai-lai-bo-tron\n",
            "\n",
            "200\n",
            "ComicData/tu-do-trong-mo\n",
            "\n",
            "200\n",
            "ComicData/em-chi-muon-hit-van-khi-cua-anh\n",
            "\n",
            "200\n",
            "ComicData/kiep-nay-toi-nhat-dinh-tro-thanh-gia-chu\n",
            "\n",
            "200\n",
            "ComicData/lan-nua-toa-sang\n",
            "\n",
            "200\n",
            "ComicData/the-thao-cuc-han\n",
            "\n",
            "200\n",
            "ComicData/tro-thanh-co-chau-gai-bi-khinh-miet-cua-gia-toc-vo-lam\n",
            "\n",
            "200\n",
            "ComicData/su-phan-boi\n",
            "\n",
            "200\n",
            "ComicData/cha-oi-con-khong-muon-ket-hon-dau\n",
            "\n",
            "200\n",
            "ComicData/cuoc-hon-nhan-nay-du-sao-cung-se-tan-vo-ma-thoi\n",
            "\n",
            "200\n",
            "ComicData/dai-quan-gia-la-ma-hoang\n",
            "\n",
            "200\n",
            "ComicData/quyen-ru-papa-cua-nhan-vat-phan-dien\n",
            "\n",
            "200\n",
            "ComicData/bao-ve-sieu-sao-cua-toi\n",
            "\n",
            "200\n",
            "ComicData/giao-duc-chan-chinh-get-schooled\n",
            "\n",
            "200\n",
            "ComicData/bac-kiem-giang-ho\n",
            "\n",
            "200\n",
            "ComicData/toi-sap-ly-hon-voi-nguoi-chong-doc-ac-nhung-chung-toi-co-baby\n",
            "\n",
            "200\n",
            "ComicData/cuop-dau\n",
            "\n",
            "200\n",
            "ComicData/chainsaw-man-tho-san-quy\n",
            "\n",
            "200\n",
            "ComicData/hom-nay-cong-nuong-toan-nang-cung-thay-chan-nan\n",
            "\n",
            "200\n",
            "ComicData/tinh-giap-hon-tuong\n",
            "\n",
            "200\n",
            "ComicData/toi-tro-thanh-thu-ky-cua-bao-chua\n",
            "\n",
            "200\n",
            "ComicData/phuong-phap-khien-phu-quan-dung-ve-phia-toi\n",
            "\n",
            "200\n",
            "ComicData/nong-long-muon-giay-vo-em\n",
            "\n",
            "200\n",
            "ComicData/xam-nhap-vao-truong-trung-hoc-tai-phiet\n",
            "\n",
            "200\n",
            "ComicData/khi-doi-chan-thoi-buoc\n",
            "\n",
            "200\n",
            "ComicData/cao-vo-ha-canh-den-mot-van-nam-sau\n",
            "\n",
            "200\n",
            "ComicData/toi-phai-giau-em-trai-truoc-da\n",
            "\n",
            "200\n",
            "ComicData/toi-da-co-chong-sau-khi-nhat-duoc-nam-chinh\n",
            "\n",
            "200\n",
            "ComicData/nguoi-tu-tien-tai-do-thi\n",
            "\n",
            "200\n",
            "ComicData/ac-nu-hom-nay-lai-yeu-doi-roi\n",
            "\n",
            "fetching 2\n",
            "\n",
            "status 200\n",
            "200\n",
            "ComicData/vung-trom-giau-khong-duoc\n",
            "\n",
            "200\n",
            "ComicData/mato-seihei-no-slave\n",
            "\n",
            "200\n",
            "ComicData/tien-vo-de-ton\n",
            "\n",
            "200\n",
            "ComicData/tro-thanh-vo-thai-tu-quai-vat\n",
            "\n",
            "200\n",
            "ComicData/toan-tri-doc-gia-omniscient-reader\n",
            "\n",
            "200\n",
            "ComicData/oshi-no-ko\n",
            "\n",
            "200\n",
            "ComicData/khong-the-thoat-khoi-nguoi\n",
            "\n",
            "200\n",
            "ComicData/chu-thuat-hoi-chien\n",
            "\n",
            "200\n",
            "ComicData/moi-lien-ket-giua-bao-den-va-be-tho\n",
            "\n",
            "200\n",
            "ComicData/ket-thuc-cua-nhan-vat-phan-dien-chi-co-the-la-cai-chet\n",
            "\n",
            "200\n",
            "ComicData/than-vo-thien-ton\n",
            "\n",
            "200\n",
            "ComicData/bao-chua-be-con\n",
            "\n",
            "500\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "the JSON object must be str, bytes or bytearray, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfetchData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mfetchData\u001b[1;34m(start, end)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m oneComic \u001b[38;5;129;01min\u001b[39;00m flat_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomic\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     67\u001b[0m         urlComic \u001b[38;5;241m=\u001b[39m oneComic[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murlComic\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 68\u001b[0m         JsonComic \u001b[38;5;241m=\u001b[39m \u001b[43mGetComicJSON\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlComic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m         SaveJSON(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComicData/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murlComic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,JsonComic)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ListComic\n",
            "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mGetComicJSON\u001b[1;34m(urlComic)\u001b[0m\n\u001b[0;32m     10\u001b[0m selector \u001b[38;5;241m=\u001b[39m Selector(text\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     11\u001b[0m json_data \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mcss(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript[type=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]::text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m---> 13\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m expression \u001b[38;5;241m=\u001b[39m jmespath\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    {\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m flat_data \u001b[38;5;241m=\u001b[39m expression\u001b[38;5;241m.\u001b[39msearch(data)\n",
            "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
            "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not NoneType"
          ]
        }
      ],
      "source": [
        "fetchData(1, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sau-K857kUnw"
      },
      "outputs": [],
      "source": [
        "for oneComic in flat_data[\"comic\"]:\n",
        "  print(oneComic[\"urlComic\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30U8t23iND8j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TJ2kL1GtKg2"
      },
      "outputs": [],
      "source": [
        "GetChapterOfComicJSON(\"cuop-dau\", chapter=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Iipo8GwjsCvH"
      },
      "outputs": [],
      "source": [
        "def GetChapterOfComicJSON(urlComic, chapter=1):\n",
        "  response = requests.get(f'https://doctruyenonline.vn/truyen-tranh/{urlComic}/chapter-{chapter}')\n",
        "  print(response.status_code)\n",
        "  \n",
        "  selector = Selector(text=response.text)\n",
        "  json_data = selector.css(\"script[type='application/json']::text\").get()\n",
        "  data = json.loads(json_data)\n",
        "  expression = jmespath.compile(\n",
        "      \"\"\"\n",
        "      {\n",
        "        \"Page\": props.pageProps.dataContentChapter[*].{indexImg:indexImg,imgChapter:imgChapter}\n",
        "      }\n",
        "      \"\"\"\n",
        "  )\n",
        "  flat_data = expression.search(data)\n",
        "  return flat_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HvukkrrrVdGg"
      },
      "outputs": [],
      "source": [
        "JsonComic = GetComicJSON(\"toi-se-bi-tru-khu-cung-hoang-de\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8wWdzVMgYki"
      },
      "outputs": [],
      "source": [
        "JsonComic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6PmiNoAZOTl"
      },
      "outputs": [],
      "source": [
        "# encodedUnicode = json.dumps(JsonComic, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iewol4Q7CDRe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKiD8NGAEtED"
      },
      "outputs": [],
      "source": [
        "import unidecode\n",
        "import re\n",
        "def CreateSlug(accented_string:str):\n",
        "\n",
        "  # accented_string is of type 'unicode'\n",
        "  unaccented_string = unidecode.unidecode(accented_string).lower()\n",
        "  unaccented_string = re.sub(r\"[^\\w\\s]\", '', unaccented_string)\n",
        "  unaccented_string=re.sub(r\"\\s+\",\"-\",unaccented_string)\n",
        "  return unaccented_string\n",
        "\n",
        "CreateSlug(\"Tu Ti\\u00ean \\u1ede Th\\u1ebf Gi\\u1edbi Si\\u00eau N\\u0103ng L\\u1ef1c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPz6vb0Qh1oV"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Assuming we have an HTML document in the 'html_content' variable\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find the desired element and extract its text using get_text()\n",
        "elements = soup.find_all('span',itemprop=\"name\")\n",
        "\n",
        "#get_text with strip set to true\n",
        "for idx,element in  enumerate(elements):\n",
        "  print(f\"({idx},{element.text})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
